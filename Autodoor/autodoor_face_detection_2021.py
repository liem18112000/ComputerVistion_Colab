# -*- coding: utf-8 -*-
"""Copy of Autodoor_Face_Detection_2021

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kNxoyoMuiz12DRTlIpyZcL9eYBaqQv1e

# Custom Facial Verification Project

## 1. Import data from github
"""

!git clone https://github.com/liem18112000/facemask_data.git

!nvidia-smi

"""## 2. Import libraries and create global parameters"""

# Import libs
import numpy as np
import tensorflow as tf
import shutil
import os
import random
import matplotlib.pyplot as plt

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from os import path

# Global variables
IMAGE_SIZE = (224, 224)
INPUT_SHAPE = [224, 224, 3]
TRAIN_SIZE = 1000 
TEST_SIZE = 80
EPOCH = 10

# Pretrained model selection
'''
    "VGG19"             :   Very Deep Convolutional Networks for Large-Scale Image Recognition (ICLR 2015)
    "MobileNetV2"       :   MobileNetV2: Inverted Residuals and Linear Bottlenecks (CVPR 2018)
    "ResNet152V2"       :   Identity Mappings in Deep Residual Networks (CVPR 2016)
    "Xception"          :   Xception: Deep Learning with Depthwise Separable Convolutions (CVPR 2017)
    "InceptionResNetV2" :   Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning (AAAI 2017)
    "DenseNet201"       :   Densely Connected Convolutional Networks (CVPR 2017)
'''
selected_models = [
    "VGG19",
    "MobileNetV2",
    # "ResNet152V2",
    # "Xception",
    # "InceptionResNetV2",
    # "DenseNet201"
]

"""## 3. Create directory for allocating data"""

# All classes
classes = [
    'Mask',
    'No Mask',
    'Wrong Mask'
]

# Assigning data paths to variables
root_dir = 'facemask_data/mask/';

for cls in classes:

    # Get data dir
    data = root_dir  + cls + "/"

    # The overall info of data in facemask_data
    total_images = os.listdir(data)
    print("Number of " + cls + "'s images : {}".format(len(total_images)))

    # Check whether train - test directories are created or not
    if(not path.isdir('./train/' + cls)):

        os.makedirs('./train/' + cls)
        print('Created directory "{}"'.format('./train/' + cls))

        os.makedirs('./test/' + cls)
        print('Created directory "{}"'.format('./test/' + cls))

        for image in random.sample(total_images, TRAIN_SIZE):
            shutil.copy(data + image, './train/' + cls)

        for image in random.sample(total_images, TEST_SIZE):
            shutil.copy(data + image, './test/' + cls)

    else:
        print('Directories : "' + cls + '" already created!')

"""## 4. Train - test data separation"""

# Data is separated into train, test datasets + normailzation + Random noises
train_batch = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip=True, vertical_flip=True, shear_range=0.2).\
            flow_from_directory('./train', target_size=IMAGE_SIZE, batch_size=10, class_mode = 'categorical')
test_batch = ImageDataGenerator(rescale=1./255).\
            flow_from_directory('./test', target_size = IMAGE_SIZE, batch_size=10, class_mode= 'categorical')

"""## 5. Build Models

### a. Pre-trained model initialize
"""

# Import desired pretrained models
from tensorflow.keras.applications import VGG19
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.applications import Xception
from tensorflow.keras.applications import InceptionResNetV2
from tensorflow.keras.applications import DenseNet201

# Call explicit prtetrained models
pretrained_models = {
    "VGG19"             :   VGG19(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False),
    "MobileNetV2"       :   MobileNetV2(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False),
    "ResNet152V2"       :   ResNet152V2(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False),
    "Xception"          :   Xception(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False),
    "InceptionResNetV2" :   InceptionResNetV2(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False),
    "DenseNet201"       :   DenseNet201(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)
}

# Set pretrain model to untrainable 
for (key, model) in pretrained_models.items():
    if key in selected_models:
        for layers in model.layers:
            layers.trainable = False

        # Overal infomation of pretrain model
        print("Overall infomation of pretrain model '" + key + "' :")
        model.summary()

"""### b. Complete overall model for facemask detection"""

# Construct model for detection
complete_models = {} 

for (key, value) in pretrained_models.items():
    if key in selected_models: 
        model = tf.keras.models.Sequential([
                    value,
                    tf.keras.layers.Dropout(0.5),
                    tf.keras.layers.Flatten(),
                    tf.keras.layers.Dense(4096, activation='relu'),
                    tf.keras.layers.Dense(1024, activation='relu'),
                    tf.keras.layers.Dense(len(classes), activation='softmax')
                ])
        complete_models.update({
            key :  model
        })

        # Overall information of model
        print('Over model of ' + key + ' - FC')
        model.summary()

"""## 6. Model training and evaluation"""

histories = {}

for (key, model) in complete_models.items():

    print('Model "' + key + '" training : ')

    # Complie model
    model.compile(optimizer='adam',
                loss='categorical_crossentropy',
                metrics=['accuracy'])

    # Train model
    history = model.fit(train_batch, validation_data=test_batch, epochs=EPOCH)

    # History update
    histories.update({
        key : history
    })

for (key, history) in histories.items():

    print("Train accuracy of " + key + " :")

    # summarize history for accuracy
    plt.plot(history.history['accuracy'], label='train acc')
    plt.plot(history.history['val_accuracy'], label='val acc')
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')

    # Show plots 
    plt.show()

    print("Loss of " + key + " :")

    # summarize history for loss
    plt.plot(history.history['loss'], label='train loss')
    plt.plot(history.history['val_loss'], label='val loss')
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')

    # Show plots 
    plt.show()

for (key, model) in complete_models.items():

    # Model evaluation
    print("Evaluate on test set : ")
    results = model.evaluate(test_batch, batch_size=128)
    print("Model '" + key + "' accuracy : ", results[1] * 100, "%")

"""## 7. Save model"""

model_dir = 'trained_model'

for (key, model) in complete_models.items():

    # Save model - h5 format
    file = model_dir + '/' + key + 'me_verification.h5'
    model.save(file)
    print('Save model to : ' + str(file))

# JSON format for web application
!pip install tensorflowjs
!tensorflowjs_converter --input_format=keras trained_model/VGG19me_verification.h5 compliled_model/VGG19me_verification